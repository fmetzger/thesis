%!TEX root = ../../dissertation.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Recent Developments in the Mobile Network Stack}
\label{c5:sec:stack-enhancements}


Contrary to the popular scientific belief, that the Internet is unable to change and renew itself (so called Internet ``ossification'', compare, e.g., \cite{feldmann2010ossification}), protocols in the \gls{TCP}/\gls{IP} stack change all the time. Changes are more likely to occur in the end-to-end stack behavior and not in the packet format, as they are more difficult to change. New application requirements and changing network architectures always trigger adaptations in the stack in-between. 

This section briefly covers the existing protocol stacks in relation to mobile networks and streaming, new protocols and how they might influence the stack, and also discusses \gls{TCP} more closely as an example. Beneficial interactions between the stack's layers are presented in a final part.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Influences of the Existing Stack}

Superficially not much has changed in the Web's protocol stack. There is still \gls{IP}, \gls{TCP}, and \gls{HTTP} forming effectively the same protocol stack since 1991 with HTTP/0.9. And this seems hard to change, especially the transport layer is fixed to \gls{UDP} and \gls{TCP}, everything else will probably get rejected, altered or even dropped by one of the numerous middleboxes, such as \glspl{NAT}, or forced ``traffic optimization'' transparent proxies, all of which are especially prevalent in mobile networks \cite{sigcomm11middleboxes}. As a side note, this adds another layer of state kept in the network. A fact that was already discussed as being highly problematic and capable of inducing load in the core network in Chapter~\ref{chap:mobilenets}.

Each protocol, representing a layer in the stack, characteristically contributes to influencing data transmissions and varies in its degree of impact on the network as well as the intended goal of the transmission (e.g., streaming and watching a video).

Time scales



%%%% NSN insert
Associated with each layer, and with the actual application running on top of the stack as well, are different timing constraints or time constants of control. Figure~\ref{c5:fig:timescales} overviews the approximate time scales on which activities take place, spanning a remarkable range of twelve orders of magnitude.
To appraise the complexity introduced by stacking multiple layers on top of one another, consider that many layers introduce their own notion of control. Multiple layers might implement the same or similar functionality, e.g. flow control in the application and on transport layer, leading to nested control loops, which might be coupled due to the timing constraints. As such, the aim of this deliverable is to provide a methodology that identifies influencing factors on the user experience, and quantifies the relative impact of these factors.

\begin{figure}[htb]
	\centering
	\includegraphics[width=\textwidth]{images/timescales-placeholder.pdf}
	\caption{[PLACEHOLDER] Discernible time scales the network layer protocols operate on.}
\label{c5:fig:timescales}
\end{figure}

%Mobile Network Influences
From the perspective of end-user \gls{IP}, \gls{LTE} represents yet another host-to-network technology that transports packets. Still, there are effects of wireless technology and mobile network specific behavior that differ from the wireline notion of a ``dumb'' underlying bit pipe.
On one side, there are typical effects of wireless connectivity relating to physical phenomena like fading and interference. Flaky radio connectivity is a major source of packet loss and excessive delay. Then, the technological progress enables both handsets and the network to become faster: Comparing the delay budgets given by for \gls{HSDPA} respectively, it is seen that the delay caused by processing on the mobile terminals decreased by a factor of 30, and that the core network has become faster by an order of magnitude as well. \cite{laner2011dissecting3gdelay} has additional information on the delay budgets per network entity, varying the packet size as the parameter.
\gls{LTE} also makes heavy use of the concept of bearers, a type of tunnel through the mobile network associated with quality levels and policy control. Although the bearer concept already exists in \gls{UMTS}, operators seem cautious to configure other bearers than the default one, and support by handsets is not widespread either. The \gls{LTE} bearer setup procedure is sufficiently lengthy to be measurable and influence packet delay on initiating connections \cite{arlos2010packetsizedelayinfluence}. 
For reasons of radio spectrum efficiency, applications with long patterns of inactivity may be scheduled to not use \gls{HSDPA}. This also causes measurable additional delay for applications.
There are lots of controls for mobile operators to engineer traffic flows in their networks. In \cite{sigcomm11middleboxes}, the authors show artifacts relating to port and network address translation (commonly subsumed under ``NAT''), firewalling, IP address assignment etc. Operators can also employ traffic engineering on backhaul links, and use policies to better support (or regulate) specific services for specific users or user groups, schedule traffic at different times of the day, etc.

%Transport Protocol Influences
The application and associated application-layer protocols dictate certain requirements on the transport protocol to be used. The two most widely used transport protocols are \gls{TCP} and \gls{UDP}.
\gls{TCP} implements a number of elaborate mechanisms to establish and tear down connections, deliver data to the application in sequential order, conceal loss on the network layer, adapt its bandwidth usage to the capabilities of the other endpoint (flow control) and the network (congestion control), and share bandwidth fairly through a distributed control algorithm. Furthermore, its notion of ports adds a layer of addresses on top of the network layer.
\gls{UDP} also supports port numbers, but does not include any of the other mechanisms \gls{TCP} has. This spurs the common misconception that \gls{UDP} is the ``faster'' transport protocol. In fact, all packet types are subject to the same round-trip time, independent of the transport protocol used. Delays in the delivery of data to the upper layer occur in \gls{TCP} when segments are considered lost in transmission. \gls{TCP} retransmits the lost segments, causing the round-trip time to spike temporarily. In the case of \gls{UDP}, the application layer handles (or ignores) packet loss. If loss is treated, the same performance limitations like for \gls{TCP} apply.
\gls{TCP}'s method of detecting loss deserves description as well. Segments are considered lost if either ACKs for the preceding and succeeding segments were received (SACKs), or the ACK for the segment is overdue, causing a timeout. Thus, \gls{TCP} cannot discriminate loss of ACK segments from actual packet loss, nor does its assumption of loss hold in the face of highly varying delays, i.e. jitter, as typically found in mobile networks.

%Application Layer Protocols
There exists a diversity of streaming applications and associated application-layer protocols, each supporting to differing degrees certain types of streaming, and each having its own set of requirements:
\begin{itemize}
\item Content type --- Pre-generated (as for example in case of video sharing web sites) or live (e.g. televised sports events, news feeds)
\item Codec --- adaptive, variable, or constant media bitrate
\item Playback control and quality feedback --- client/server-side, implicit/explicit
\end{itemize}
Adhering to the design space limits present on the Internet, most innovation takes place on the application layer.

%Application Behavior
As indicated in Figure~\ref{c5:fig:timescales}, the time scale on which streaming applications buffer content lie in the range of seconds. This is a necessity in a best-effort network, as the available network bitrate might drop unexpectedly and could drain a shallower buffer quickly. On the other hand, given sufficient bandwidth or even bandwidth guarantees as demanded in \gls{LTE}, buffer sizes could be reduced, improving interactivity of the stream and enabling closer-to-realtime live streaming or conferencing.
Buffering and playback strategies in current applications are such a pivotal point in the operation of video streaming in mobile networks. The application behavior represents a trade-off between different types of perceivable artifacts --- initial startup delay, stalls, (partial) media skips (e.g. continuous audio, but skipping video), and quality adaption.

%Cross-Layer Influences
Layered network models often assume the functional separation of network layers. The timescales shown in Figure~\ref{c5:fig:timescales} partly support this notion, but also show that there are conflicts in the speed of control loops that can be implemented. Indeed, actual protocols and hardware need to be aware of and often explicitly exploit cross-layer influences and information flow.
\gls{TCP} is an example for this: Its tracking of a congestion window reflects not the state of the transport, but of the network and lower layers. Congestion is assumed by \gls{TCP} if segments are lost (or unduly delayed) below the transport layer. Consequently, if loss happens on the lower layers for reasons other than congestion, \gls{TCP} reacts in an inappropriate way. As indicated in the previous section, loss and delay spikes may have many root causes in a wireless network, and loss might be concealed altogether through lower-layer retransmission methods.
Another example concerning \gls{TCP} is the \gls{PMTU} discovery. Here, \gls{TCP} probes the largest segment size that can be transmitted by the host-to-network layer in one transmission, e.g., Ethernet frame, using \gls{IP}'s ``Don't Fragment'' signaling. Again, a mobile network does not behave the same way an \gls{IP}/Ethernet-based network would work, as it conceals its actual \gls{MTU} and reports it can transport full Ethernet frames.
In addition to (probably inadvertent) behavioral differences between ``classical'' wireline / Ethernet-based and cellular mobile Internet, an \gls{LTE} mobile network typically lies within the administrative domain of one single operator, and thus offers significantly more control over data flows. Through appropriate policies tailored to the user, their subscription model, and other factors such as the overall network status, bearers in the network can be configured for all types of services. Depending on the bearers' quality settings, the operator can support (or, to the contrary, penalize) streaming traffic.

The problem of protocols drawing wrong conclusions due to wireline assumptions has been described for \gls{TCP} above. It is foreseeable that a similar set of problems will appear when operators enforce different policies on Internet-based services without checking first the applicability of their traffic engineering methods. The methodology presented in this deliverable will help to understand beforehand the effects on the user that bearer quality settings have. Similarly, the methodology will present a set of tools to judge before engineering new hardware the capability of certain controls envisioned by the standards bodies, and if an implementation would turn out useful for a set of streaming services.
%%% end insert





 Influence of L1/2/3 layer protocols and mechanisms (IPv4/6, tunneling, ethernet vs RLC/RRC/NAS, ...)


using TLS or not

Firefox Patch: Sort Idle HTTP Connections by CWND \cite{ffSortCWND}



Another undesirable side-effect of middleboxes, but also of any other network node on the path are overdimensioned packet buffers and the bufferbloat effect caused by them.

%%
Bufferbloat, Congestion Control, and AQM Effects on Reliable Mobile Streaming

 ECN~\cite{rfc3168} (one of the earlier notions of cross-layer interactions; disabled by default almost everywhere)

Comparison of end-to-end and network-supported fast startup congestion control schemes \cite{scharf2011comparison}

Bufferbloat: Dark Buffers in the Internet \cite{gettys2011bufferbloat}

Detecting and quantifying bufferbloat in network paths \cite{groenewegen2011detecting}

Congestion avoidance and control \cite{jacobson1988congestion}

Controlling Queue Delay \cite{Nichols:2012:CQD:2209249.2209264} CoDel\cite{nichols2014codel}
 TCP needs congestion loss to determine bottleneck line speed
	too much buffering hinders this
 Memory is cheap, so why not put in some more megabytes
 Home router buffer induced latency can be as high as several seconds
CoDel:
 Head drop not tail drop
 Queues only as shock absorbers
 What matters is the delay within a flow
 CoDel measures minimal packet pass through time in the local device buffer during a defined interval
 If minimum gets too high, too much buffering is happening
 If delay value does not once fall below a target in the interval CoDel will start dropping packets
	Signals congestion and hopefully reduces source rate
	If stays above target, progressively more packets are dropped
	Target: 5ms; interval: 100ms, based on simulation results
 Can be enabled in Linux since 3.5, but many NIC drivers do not support it yet
 Every buffer along the path influences transmission
	Most impact on the node before the bottleneck
	Cell towers, dsl/cable modems, ...




Characteristics of UDP packet loss: Effect of tcp traffic \cite{sawashima97characteristics}


%%
Mobile Network Architectures, end-to-end Protocol Stacks and their sensitivity to Middleboxes



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Upcoming Protocols and Streaming Relationship}

Improvements to congestion control for mobile streaming?


 Alternative modes of transport (e.g. DCCP, , RED, Google's SPDY or new approaches)

 Alternate Transport Protocols (DCCP\cite{rfc4340}, LEDBAT\cite{rfc6817}/$\mu$TP\cite{bt2010utp}, QUIC, SCTP~\cite{rfc4960}, DTLS~\cite{rfc6347})

but successful protocols develop de-facto; de jure much harder (see \gls{3G})



 End-to-end encryption and Authentication mechanisms (e.g.IPSec~\cite{rfc4301}, DNSSEC~\cite{rfc4033}, \gls{DANE}~\cite{rfc6698})


\gls{QUIC}  Quick UDP Internet Connections; protocols without retransmission feature (lost packets are not relevant and cause head-of-line blocking) but still with the all-important congestion control + TLS
%http://www.ietf.org/proceedings/88/slides/slides-88-tsvarea-10.pdf
\footnote{\url{http://lwn.net/Articles/558826/}}
UDP based for now, could very well end up as modifications to future TCP
inherits new TCP features such as TFO, snap start, ...
avoids most retransmissions through FEC
congestion control not through CWND but through packet pacing
includes stream multiplexing and TLS-like crypto by default



WebSocket \cite{rfc6455}
WebSockets as streaming transport \cite{w3c2011websockets} \cite{heise2011websockets}
 IETF HyBi (Hypertext Bidirectional) Working group
 W3C WebSocket API
 Supported by every major browser and Web server
 Provides full-duplex client-server communication
	Upgrades from HTTP/1.1 through extension header
	Barebone protocol atop TCP (or TLS), not HTTP
	HTTP/1.1 only allows client-initiated polling (GET)
	Asynchronous server push possible
		In HTTP/1.1 only achievable through various hacks (e.g. ``long polling'')
		Stateful instead of stateless (as HTTP)
Lower overhead per transmission/frame
Reduces number of open TCP connections and bandwidth overhead (no polling on additional TCP connection)


WebRTC \cite{webrtcdraft}


SPDY: An experimental protocol for a faster web \cite{google2011SPDYdef} and \cite{google2010SPDYwp} 
SPDY / \gls{HTTP}/2.0 (multiplexing -> segmented streaming)
 Google proposal and draft
	Currently SPDY/3.1 
	IETF httpbis working group basis for http/2.0
 original Draft based on Chrome browser implementation
 Widespread use and implementations
	Chrome, Firefox; Apache, Nginx
	Google, Twitter, Facebook, Akamai, Wordpress, ...
	HTTP-requests are transparently upgraded through Next Protocol Negotiation
 TLS mandatory
 HTTP/1.1 syntax still viable as a layer on top of SPDY
 Aim: Just one connection held per domain
	Better server scaling (less concurrent connections, fewer packets sent)
	Better latency
Multiplexing/Streams:
 Control and Data Frames, with header compression
 Stream interleaving/multiplexing or cancellation
 Server hint
	Server informs client, what he might want to request in the near future
 Server created streams / server push
	Avoiding one additional RTT and polling
	Only data pushed related to possible GET requests
	Client-side throttles to prevent ``push attacks''
 Stream priorities (8 levels)
	Prefer essential resources over others (images)
	Prefer data with earlier deadlines? (E.g. load next few video streams immediately while already requesting more)
 Use with Scalable Video Coding (Base Layer vs Enhancement Layers)?
 Per stream flow control
multiplexing:
 HTTP: One file request after another
	Pipelining usually absent or disabled by default in browsers (Chrome, Firefox, IE)
	High complexity/maintenance, low gain, head-of-line blocking issues
 SPDY: File parts reordered according to timelines
	Out of order and interleaved requests
Evaluations:
	Average reduction in page load time: ~29\%; 27\% - 60\%
	Strongly dependent on connection, server environment
	HTTP/1.1 optimization (resources split on multiple domains) prevents SPDY multiplexing gains
 SPDY could be more susceptible to packet loss and TCP congestion window downscaling
	Only one connection used compared to multiple HTTP/1.1
 Possible operator benefits
	Significant reduction in concurrent TCP sessions
	Reduction in packets per second
	$\rightarrow$ Reduced infrastructure load?
spdy mobile page load times
 Chrome on Android tests with several Websites
 Emulated mobile conditions (constant 2Mbps, 150ms RTT)
 ~23\% average load time reduction
 Benefits can be higher for large RTT
	Less request round trips and connection setups needed



HTTP/2.0~\cite{http20draft}
 HTTP/1.0 defined in 1996, 1.1 in 1999
	Since then no changes changes to the core protocol
 Many long standing issues with HTTP/1.1, e.g.
	Problems with ``long fat pipes''
		Many parallel connections as workaround
		Fairness issues
	Large overhead for small requests
 IETF Hypertext Transfer Protocol Bis Working Group
 Initial call for proposals made in March 2012
 Planned 2.0 standard proposal in 2014/2015
 Using SPDY as a starting point
 General aims
	Tackle multiplexing, improve load times and experienced latency
	But preserve the semantics of HTTP/1.1
requires presence (but not usage) of TLS1.2
	if used, emphemeral cipher suites >=2048 must be used (a.k.a. Perfect Forward Secrecy)












%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The TCP Case: Prime Example of a Living, Ever-Evolving Protocol}

\gls{TCP} changes (Fast Open, IW10, ...; any relationship to streaming? maybe faster)

TCP modifications for short-lived connections (e.g. initially ignore congestion avoidance and push a lot of data at once (google.com approach, Increasing TCP's Initial Window)) 

IW10: better response time, still fair \cite{rfc6928}
An argument for increasing \gls{TCP}'s initial congestion window \cite{dukkipati2010argument}
IW3, IW10  Initial window size (IW10, ...)
 TCP Congestion Window
	Maximal number of packets in flight
–	Scaling through congestion control and avoidance algorithms
 Initial Value
	1 (RFC1122, RFC2001)
	4000 Bytes (~ 3 packets) (RFC2414, RFC3390, ~2002)
	IETF proposal: IW10 (Google Draft 2010-2012)
 Rationale
	HTTP request for small websites using new TCP connection
	Transmit whole site in one RTT instead of multiple
	Reduces average latency
		Evaluation: ~10\% page load reduction on typical web pages
	High IW values already used by many CDNs



TCP Fast Open~\cite{cheng2014tcptfo}
 IETF draft
 Linux 3.6 client side implementation (September 2012)
 Linux 3.7 server side (~ 2012)
 Small server-side application adaptation required
 Send data in the SYN and SYNACK packets
	Deliver it immediately to the application
	Only allowed for subsequent connections, requires additional security cookie (specific to client-server IP pair)
 Saves one initial RTT
 4\% to 41\% popular web page load time improvement


1s / 3s Retransmission Timeout \cite{rfc6298}
 TCP retransmission timeout set through RTT measurement
 Default value needed for timeouts during handshake: 3 seconds (now obsolete RFC1122, RFC2988)
 RFC 6298, Linux 3.1 (October 2011)
	Reduce TCP initial retransmission timeout to 1 second
 Improves TCP handshake times for lossy networks
 Benefits for short-lived (Web) transactions


Proportional Rate Reduction PRR (vs. rfc 3517)
 TCP behavior on packet loss in the past
	RFC 3517: reduce CWND to half
		Must first ACK large portion of the data still in flight before transmitting again
	Linux: ``Rate halving''; Reduce CWND by 1 on every ACK until CWND/2
		Can still send data during recovery
 Google IETF Proposal (Linux 3.2, January 2012): PRR
	Reduce timeouts by avoiding excessive window reductions
	Converge to cwnd chosen by congestion control by the end of recovery
	Can improve packet loss recovery time and average latency



TCP Early Retransmit \cite{rfc5827} Kernel 3.5 (July 2012)
 TCP loss recovery (not using SACK) triggers on
	Timeout (may be lengthy, ~RTT, min 1s)
	Triple duplicate ACK (fast retransmit)
		If CWND is small, TCP may not be able to get enough DUPACKs to trigger
		Reduce DUPACK threshold for these connections
 Reduce DUPACK threshold for these connections
	Less robust to segment reordering
 Reduces average latency for narrow and lossy connections

Multipath TCP MPTCP~\cite{rfc6824}!


Congestion Avoidance algorithm ((New Reno~\cite{rfc6582}, Vegas~\cite{Brakmo:1994:TVN:190809.190317}, Compound~\cite{song2006compound}, BIC, CUBIC~\cite{ha2008cubic}; all w or w/o SACK)
general basic tcp congestion control in \cite{rfc5681}, describing Reno

Slow Start~\cite{rfc5681}
 HyStart~\cite{Ha20112092}


Nagle's Algorithm~\cite{rfc896} delaying and aggregating small data packets


OS-dependent receive window scaling behavior

OS-dependent choice of packet size


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Proposal for Cross-Layer Enhancements}
\label{c5:crosslayerhinting}


Wired Internet access has a very narrow choice of protocols on the \gls{ISO}/\gls{OSI} Layers 1 and 2. The typical use-case consists of a \gls{LAN} using Ethernet which is then tunneled through or translated into one of several access technologies, e.g., \gls{DSL}, \gls{DOCSIS}, or \gls{PON}. Applications often make assumptions that rely on the presence of these protocols and their specific characteristics.

However, Internet access today is similarly often achieved using mobile cellular networks. The latest standardized iteration of these is \gls{LTE} and the accompanying \gls{EPS} core network infrastructure \cite{olsson2009sae}. This is the first evolution of standards that completely removes the classical circuit switched domain making room for more radio frequency bandwidth to be used with the all-\gls{IP} services achieving shared transmission capacities --- comparable to today's 802.11n WiFi --- albeit on much larger cell sizes of \SI{1}{\kilo\meter} to \SI{3}{\kilo\meter}. The \gls{EPS} network acts as an intermediary between the radio access stations and the Internet enabling strong traffic control mechanisms as well as mobility anchored at the \gls{SGW}. Traffic is routed through the core by using tunneling over the \gls{SGW} and \gls{PGW} based on the traffic bearer concept defined either in the \gls{gtp} or the \gls{PMIPv6} protocols. For every mobile device connected to the network there is one default and up to ten dedicated bearers carrying traffic filtered by pre-set \gls{QoS} parameters. Control is enforced through a logically separate network control plane, that is also used to setup and tear down these bearers. Figure fig:ltestack displays the disparity between the Internet's protocol stack and that of an \gls{LTE} network encapsulating all user traffic in additional protocol layers by the tunneling process.

Research work is ongoing how to best work with this complex network setup. It is expected, that with the rise of mobile access the core network comes under heavy traffic pressure with negative affects on the \gls{QoS} of best-effort traffic. Endeavors are required to study the loaded network's behavior. Also very little work has gone into exploring the control plane characteristics of these networks, including their performance. A novel approach could also be, to make mobile device applications, e.g. video streaming players, aware of the core networks capabilities and allow the request of tunnels tailored to their specific \gls{QoS} requirements resulting in a possible increase of perceived quality.

% influence of signaling plane and core network elements - scaling

The protocols used for the radio transmissions behave very differently when compared to Ethernet and assumptions made by higher layers may not hold any more. This can apply to, e.g., reliability, frame sizing and fragmenting, and latency amounting to undesired effects on higher-layer traffic. For example, loss in \gls{GSM} and \gls{UMTS} networks is often caught transparently on layer 2 and a retransmission is conducted. However, in the time the retransmission takes the transport layer may have already run into a timeout and re-requested the missing segment on its own, resulting in additional delay and a waste of bandwidth. This is especially detrimental for time-critical applications like video streaming, possibly resulting in buffer underruns and degraded quality. Transport and application layer mechanisms need to be able to understand this and cope with the effects. E.g., \gls{TCP} retransmissions and congestion control could be adjusted in the course of understanding this.

Furthermore, traffic could be avoided during cell handover occurrences. This would require cross-layer cooperation and an awareness of the application when an handover is supposed to occur. The application then could schedule its traffic accordingly. Traffic falling into a handover is subject to especially high latency and loss because the mobile network acts as a mobility anchor which needs to internally reroute incoming traffic to the mobile device's new position. \gls{HTTP} traffic is especially suited to this scheduling behavior because of its statelessness and consistence of small objects that can be requested and transferred independently.


\subsubsection{Related Work}

\begin{itemize}
	\item Cross-layer design optimizations in wireless protocol stacks \cite{Raisinghani2004720}
	\item ECLAIR: An efficient cross layer architecture for wireless protocol stacks \cite{raisinghani2004eclair}
	\item Still no implementation of ECLAIR: ``Cross-layer feedback architecture for mobile device protocol stacks'' \cite{1580937}
	\item 802.21
	\item A multi-layer mobility management architecture using cross-layer signalling interactions\cite{wang2003multi}
	\item 
		\begin{itemize}
			\item \gls{DLEP} \cite{ietf2013dlepdraft}
			\item running on routers for communication between routers and attached interfaces (wireless!)
			\item interface/modem informs router about link characteristics
			\item router acts upon this information
			\item specific set of required and optional signals (message types / reason for messaging) and data items (information)
			\item bandwidth, latency, connection status (loss)
			\item information about specific neighbors
			\item \gls{UDP}-based, discovery mechanism via multicast, session-based
			\item requires/relies on lower layer auth/crypt
			\item no data items specific for cell-type mobile nets and mobility
			\item best suited for routers with external modems/interfaces (outside antennas)
		\end{itemize}
	\item Seamless Mobility in Heterogeneous Wireless Networks \cite{zarai2010seamless}
	\item Radio resource management in emerging heterogeneous wireless networks \cite{Piamrat20111066}
	\item Improved community network node design using a DLEP based radio-to-router interface \cite{6379143}
	\item Cross-layer signalling for next-generation wireless systems \cite{1200522}
	\item Cross-layer design for wireless networks \cite{1235598}
	\item A cautionary perspective on cross-layer design \cite{1404568}
	\item User-centric mobility management for multimedia content access \cite{bolla2011usercentric}
	\item Socketless \gls{TCP} --- an end to end handover solution \cite{1635680}
	\item SATSIX cross-layer architecture \cite{4656786}
	\item mostly routing protocol optimization oriented ``A cross layer based QoS model for wireless and mobile ad hoc networks'' \cite{krishna2007cross}
	\item SmoothIT mechanisms; lower layer elements provide information to higher layers, overlays\footnote{\url{http://www.smoothit.org}}  \cite{oechsner2009pushing}
	\item ``Mobility Awareness'' \cite{hummel2010mobilitaet} PMLAR (Predictive mobility and location-aware routing protocol in mobile ad hoc networks)
	\item Automatic Multi-interface Management Through Profile Handling \cite{Bonnin:2009:AMM:1503496.1503498}
	\item A ubiquitous mobile communication architecture for next-generation heterogeneous wireless systems \cite{1452832} (supposed to propose a function that determines the best handover initiation time in order to avoid early or late initiations)
	\item Optimized video streaming over 802.11 by cross-layer signaling \cite{1580941}
	\item LCP Link Control Protocol, PPP extension RFCs \cite{rfc1570,rfc1661}
 	\item Modem Link Properties Advertisement Protocol\footnote{\url{https://tools.ietf.org/html/draft-ivancic-mobopts-modemlpa-01}}
	\item IEEE 802.21 cooperative handovers, but with required network support
	\item LISP and other mobility approaches \cite{rfc6830}
	\item Radio Resource Management RRM
		\begin{itemize}
			\item resource monitoring, decision making, decision enforcement
			\item choose available wireless interfaces  best suited for a specific task
			\item rudimentary implementations in mobile OSs
		\end{itemize}
\end{itemize}




%%
\subsubsection{Cross-Layer Mobility Hinting}

Today's mobile networks are all of a cellular design. A device that moves from one cell to the other has to perform a so-called handover. During this process the device is deregistered in one cell and registered in the new one. All network traffic currently in flight has to be rerouted or relayed to the device's new location. 
Although seemingly transparent to the device's application, adverse side effects can occur during a handover, including an increase and variability of latency. 

Mobility support today always means network assisted mobility. Typically, the network decides the best possible mobility strategy from its point of view and provides infrastructure to support seamless handovers in the form of mobility anchor nodes. However, the device is actually in a very unique position, as it knows a great deal more about its traffic mix, its currently running applications and its user than the network ever could and should.
Unfortunately, most of this information remains unused, as today's network infrastructures and lower layer protocol stacks provide only very slim changes to exert control over decisions regarding the device.

Nonetheless, a lot could still be done when providing the device's operating system and application ecosystem with a simple bidirectional pathway for vertical information and control flow across network protocol layers and to other low-level systems. This work aims to do just that by providing a generic interface and exchange protocol for any kind of information relevant to an application's decision making process. With this meaningful actions and reactions of individual layers can be defined and tested. Possible use cases are provided in the next section.

Still, one has also to keep in mind, that layering and encapsulation is there for a reason and violating this is a rather risky undertaking. However, we do not think that our approach actually violates these basic principles and only extends on the ways one can communicate and interact with all individual layers without changing anything in them.


	% - Research objectives
	% 	- Bidirectional vertical information and control flow on the performance of the individual layers
	% 		- Definition of generic interfaces
	% 		- Definition of a protocol (including information types, etc.)
	% 	- Definition of meaningful actions/reactions on the individual layers (e.g. adaptation of real-time communication data sources or changes in resource allocation)

		

\subsubsection{Scenario Use Cases}

\begin{itemize}
	\item Video/Voice calls that notify the other party, that interruptions are expected to occur.

	\item Using current location data and movement patterns/predictions to improve cell selections and initiate horizontal and vertical handovers to a time suitable for the device and running applications.

	\begin{figure}[htb]
	        \centering
	        \begin{subfigure}[b]{0.90\textwidth}
	            \centering
				\includegraphics[width=\textwidth]{images/adaptive-streaming-no-cl.pdf}
				\caption{Stalling occurs without handover hinting.}
				\label{c5:fig:streaming-hinting-no-cl}
	        \end{subfigure}%

	        \begin{subfigure}[b]{0.90\textwidth}
				\centering
				\includegraphics[width=\textwidth]{images/adaptive-streaming-cl.pdf}
				\caption{Stalling can be prevented by hinting and proactively filling the playback buffer.}
				\label{c5:fig:streaming-hinting-cl}
			   \end{subfigure}%
	 \caption{Mockup of handover prediction and hinting for adaptive streaming and thus avoiding playback stalls.}
	\label{c5:fig:streaming-hinting}
	\end{figure}

	\item An adaptive streaming video application increases its video buffer when a shortly upcoming handover is announced to survive the service outage. This can be achieved by an increased rate of segment retrieval and a reduction in segment quality. The goal is to avoid any possible playback stalls due to the handover. Figure~\ref{c5:fig:streaming-hinting} demonstrates this circumstance.

	\begin{figure}[htb]
	        \centering
	        \begin{subfigure}[b]{0.90\textwidth}
	            \centering
				\includegraphics[width=\textwidth]{images/http-reorder-no-cl.pdf}
				\caption{The handover will block currently active object transmissions, page display will be delayed.}
				\label{c5:fig:http-reorder-no-cl}
	        \end{subfigure}%

	        \begin{subfigure}[b]{0.90\textwidth}
				\centering
				\includegraphics[width=\textwidth]{images/http-reorder-cl.pdf}
				\caption{The browser reorders the objects to be retrieved and avoids any transmissions during the indicated handover period.}
				\label{c5:fig:http-reorder-cl}
			   \end{subfigure}%
	 \caption{Mock-up of \gls{HTTP} reordering with handover awareness.}
	\label{c5:fig:http-reorder}
	\end{figure}

	\item Enable applications to adapt themselves to the conditions currently experienced by the networking stack and its sensors. For example, a Web browser could reorder its Website object requests to avoid sending any requests during handover periods and experience additional delay as seen in Figure~\ref{c5:fig:http-reorder}.

	\item A cross-layer enabled device can also offer a wide range of policy choices to its applications or even directly to the user. An example rule could be: ``Do not handover to a stationary WiFi from 3G when moving faster than 50km/h, only to in-vehicle WiFi.'' or ``Avoid any vertical handover, which would interrupt my service for a long time, while this VoIP call is running.''

\end{itemize}

\subsubsection{Technical Implementation}

The Implementation:
\begin{itemize}
	\item Userspace daemon that collects information from kernelspace protocol implementations and sensors and provides them to all applications.
	\item shared bus control/information system, instead of explicit comm; signaling only to interested parties
	\item provide common interface also to all available sensors and layer 1 and 2 network information and control (similar to Android)
	\item IPC message bus, possibly D-Bus\footnote{\url{http://www.freedesktop.org/wiki/Software/dbus/}} based
	\item Could extend NetworkManager\footnote{\url{https://wiki.gnome.org/Projects/NetworkManager}}, some functionality is already provided there

\end{itemize}

The process:
\begin{itemize}
\item Tell Transport/Application the expected time till handover / time of uninterrupted service
\item Tell Transport/App expected connection parameters (latency, BW, ...)
\item Application selects \gls{DASH} stream appropriate to parameters
\item Application reorders \gls{HTTP} GETs so that large GETs are not interrupted
\item Application stops transfers when handover is about to occur
\item Layer 1/2 gives a list of possible handovers to Application
\item Application selects (better: suggests) handover which fits best and reorders accordingly
\end{itemize}


\subsubsection{Planned Work and Methodology}

\begin{itemize}
	\item investigate how much information is exposed and what can already be done
	\item Analysis of data traces and realistic simulations in order to capture in detail the unwanted phenomena
	\item Verify the suitability of the State-of-the-Art algorithms and protocols which address this problem
\end{itemize}
